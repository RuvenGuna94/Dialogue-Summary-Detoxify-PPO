{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tune FLAN-T5 with Reinforcement Learning (PPO) and PEFT to Generate Less-Toxic Summaries\n",
    "\n",
    "In this notebook, you will fine-tune a FLAN-T5 model to generate less toxic content with Meta AI's hate speech reward model. The reward model is a binary classifier that predicts either \"not hate\" or \"hate\" for the given text. You will use Proximal Policy Optimization (PPO) to fine-tune and reduce the model's toxicity.\n",
    "\n",
    "## 1 - Set up Kernel and Required Dependencies\n",
    "\n",
    "Install the required packages to use PyTorch and Hugging Face transformers and datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets==2.17.0\n",
      "  Using cached datasets-2.17.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets==2.17.0) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets==2.17.0) (2.2.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets==2.17.0) (18.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets==2.17.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets==2.17.0) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets==2.17.0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets==2.17.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets==2.17.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets==2.17.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets==2.17.0) (0.70.14)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.17.0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets==2.17.0) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets==2.17.0) (0.27.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets==2.17.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets==2.17.0) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets==2.17.0) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets==2.17.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets==2.17.0) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets==2.17.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets==2.17.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets==2.17.0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets==2.17.0) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets==2.17.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from requests>=2.19.0->datasets==2.17.0) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from tqdm>=4.62.1->datasets==2.17.0) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from pandas->datasets==2.17.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from pandas->datasets==2.17.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from pandas->datasets==2.17.0) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.17.0) (1.17.0)\n",
      "Using cached datasets-2.17.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.2.0\n",
      "    Uninstalling datasets-3.2.0:\n",
      "      Successfully uninstalled datasets-3.2.0\n",
      "Successfully installed datasets-2.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "trl 0.14.0.dev0 requires datasets>=2.21.0, but you have datasets 2.17.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (24.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers==4.47.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (4.47.1)\n",
      "Requirement already satisfied: evaluate==0.4.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: rouge_score==0.1.2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from transformers==4.47.1) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from transformers==4.47.1) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from transformers==4.47.1) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from transformers==4.47.1) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from transformers==4.47.1) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from transformers==4.47.1) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from transformers==4.47.1) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from transformers==4.47.1) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from transformers==4.47.1) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from transformers==4.47.1) (4.67.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from evaluate==0.4.0) (2.17.0)\n",
      "Requirement already satisfied: dill in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from evaluate==0.4.0) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from evaluate==0.4.0) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from evaluate==0.4.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from evaluate==0.4.0) (0.70.14)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.0) (2023.10.0)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from evaluate==0.4.0) (0.18.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from rouge_score==0.1.2) (2.1.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from rouge_score==0.1.2) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from rouge_score==0.1.2) (1.17.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets>=2.0.0->evaluate==0.4.0) (18.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets>=2.0.0->evaluate==0.4.0) (0.6)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets>=2.0.0->evaluate==0.4.0) (3.11.11)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from requests->transformers==4.47.1) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from requests->transformers==4.47.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from requests->transformers==4.47.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from requests->transformers==4.47.1) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from tqdm>=4.27->transformers==4.47.1) (0.4.6)\n",
      "Requirement already satisfied: click in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from nltk->rouge_score==0.1.2) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from nltk->rouge_score==0.1.2) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from pandas->evaluate==0.4.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from pandas->evaluate==0.4.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from pandas->evaluate==0.4.0) (2024.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.0) (1.18.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/lvwerra/trl.git\n",
      "  Cloning https://github.com/lvwerra/trl.git to c:\\users\\rg255041\\appdata\\local\\temp\\pip-req-build-nu7ka0ru\n",
      "  Resolved https://github.com/lvwerra/trl.git to commit 763738f457f283270772ac9bd5b3e4027fd424d5\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: accelerate>=0.34.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from trl==0.14.0.dev0) (1.2.1)\n",
      "Collecting datasets>=2.21.0 (from trl==0.14.0.dev0)\n",
      "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: rich in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from trl==0.14.0.dev0) (13.9.4)\n",
      "Requirement already satisfied: transformers>=4.46.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from trl==0.14.0.dev0) (4.47.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from accelerate>=0.34.0->trl==0.14.0.dev0) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from accelerate>=0.34.0->trl==0.14.0.dev0) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from accelerate>=0.34.0->trl==0.14.0.dev0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from accelerate>=0.34.0->trl==0.14.0.dev0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from accelerate>=0.34.0->trl==0.14.0.dev0) (2.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from accelerate>=0.34.0->trl==0.14.0.dev0) (0.27.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from accelerate>=0.34.0->trl==0.14.0.dev0) (0.4.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets>=2.21.0->trl==0.14.0.dev0) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets>=2.21.0->trl==0.14.0.dev0) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets>=2.21.0->trl==0.14.0.dev0) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets>=2.21.0->trl==0.14.0.dev0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets>=2.21.0->trl==0.14.0.dev0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets>=2.21.0->trl==0.14.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets>=2.21.0->trl==0.14.0.dev0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets>=2.21.0->trl==0.14.0.dev0) (0.70.14)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.21.0->trl==0.14.0.dev0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from datasets>=2.21.0->trl==0.14.0.dev0) (3.11.11)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from transformers>=4.46.0->trl==0.14.0.dev0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from transformers>=4.46.0->trl==0.14.0.dev0) (0.21.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from rich->trl==0.14.0.dev0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from rich->trl==0.14.0.dev0) (2.18.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets>=2.21.0->trl==0.14.0.dev0) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets>=2.21.0->trl==0.14.0.dev0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets>=2.21.0->trl==0.14.0.dev0) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets>=2.21.0->trl==0.14.0.dev0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets>=2.21.0->trl==0.14.0.dev0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets>=2.21.0->trl==0.14.0.dev0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from aiohttp->datasets>=2.21.0->trl==0.14.0.dev0) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl==0.14.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->trl==0.14.0.dev0) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.14.0.dev0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.14.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.14.0.dev0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.14.0.dev0) (2024.12.14)\n",
      "Requirement already satisfied: networkx in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from tqdm>=4.66.3->datasets>=2.21.0->trl==0.14.0.dev0) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from pandas->datasets>=2.21.0->trl==0.14.0.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from pandas->datasets>=2.21.0->trl==0.14.0.dev0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from pandas->datasets>=2.21.0->trl==0.14.0.dev0) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl==0.14.0.dev0) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate>=0.34.0->trl==0.14.0.dev0) (3.0.2)\n",
      "Using cached datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Installing collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.17.0\n",
      "    Uninstalling datasets-2.17.0:\n",
      "      Successfully uninstalled datasets-2.17.0\n",
      "Successfully installed datasets-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/lvwerra/trl.git 'C:\\Users\\rg255041\\AppData\\Local\\Temp\\pip-req-build-nu7ka0ru'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/peft.git\n",
      "  Cloning https://github.com/huggingface/peft.git to c:\\users\\rg255041\\appdata\\local\\temp\\pip-req-build-x0gejee0\n",
      "  Resolved https://github.com/huggingface/peft.git to commit 6d458b300fc2ed82e19f796b53af4c97d03ea604\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from peft==0.14.1.dev0) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from peft==0.14.1.dev0) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from peft==0.14.1.dev0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from peft==0.14.1.dev0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from peft==0.14.1.dev0) (2.5.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from peft==0.14.1.dev0) (4.47.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from peft==0.14.1.dev0) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from peft==0.14.1.dev0) (1.2.1)\n",
      "Requirement already satisfied: safetensors in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from peft==0.14.1.dev0) (0.4.5)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from peft==0.14.1.dev0) (0.27.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from huggingface_hub>=0.25.0->peft==0.14.1.dev0) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from torch>=1.13.0->peft==0.14.1.dev0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.14.1.dev0) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from tqdm->peft==0.14.1.dev0) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from transformers->peft==0.14.1.dev0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from transformers->peft==0.14.1.dev0) (0.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from jinja2->torch>=1.13.0->peft==0.14.1.dev0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rg255041\\appdata\\local\\anaconda3\\envs\\peft\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft==0.14.1.dev0) (2024.12.14)\n",
      "Building wheels for collected packages: peft\n",
      "  Building wheel for peft (pyproject.toml): started\n",
      "  Building wheel for peft (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for peft: filename=peft-0.14.1.dev0-py3-none-any.whl size=383810 sha256=44bb30de4e45e406fa429ea56728257b1b0320a08214b67a7c7d187ee4e472c7\n",
      "  Stored in directory: C:\\Users\\rg255041\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-fyfj7de8\\wheels\\5d\\16\\61\\117d50be36b7cb532817817523554825ff840d223c0f65c2c4\n",
      "Successfully built peft\n",
      "Installing collected packages: peft\n",
      "  Attempting uninstall: peft\n",
      "    Found existing installation: peft 0.3.0\n",
      "    Uninstalling peft-0.3.0:\n",
      "      Successfully uninstalled peft-0.3.0\n",
      "Successfully installed peft-0.14.1.dev0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git 'C:\\Users\\rg255041\\AppData\\Local\\Temp\\pip-req-build-x0gejee0'\n"
     ]
    }
   ],
   "source": [
    "%pip install -U datasets==2.17.0\n",
    "\n",
    "%pip install --upgrade pip\n",
    "%pip install --disable-pip-version-check \\\n",
    "    torch==2.5.1  \\\n",
    "    torchdata==0.10.1 --quiet\n",
    "\n",
    "%pip install \\\n",
    "    transformers==4.47.1 \\\n",
    "    evaluate==0.4.0 \\\n",
    "    rouge_score==0.1.2 \n",
    "\n",
    "# Installing the Reinforcement Learning library directly from github.\n",
    "%pip install git+https://github.com/lvwerra/trl.git\n",
    "%pip install git+https://github.com/huggingface/peft.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary components. Some of them are new for this week, they will be discussed later in the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rg255041\\AppData\\Local\\anaconda3\\envs\\PEFT\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, GenerationConfig\n",
    "from datasets import load_dataset\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, TaskType\n",
    "\n",
    "# trl: Transformer Reinforcement Learning library\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead\n",
    "from trl import create_reference_model\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# tqdm library makes the loops show a smart progress meter.\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Load FLAN-T5 Model, Prepare Reward Model and Toxicity Evaluator\n",
    "\n",
    "### 2.1 - Load Data and FLAN-T5 Model Fine-Tuned with Summarization Instruction\n",
    "\n",
    "You will keep working with the same Hugging Face dataset [DialogSum](https://huggingface.co/datasets/knkarthick/dialogsum) and the pre-trained model [FLAN-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 12460\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name=\"google/flan-t5-base\"\n",
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "\n",
    "dataset_original = load_dataset(huggingface_dataset_name)\n",
    "\n",
    "dataset_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will be to preprocess the dataset. You will take only a part of it, then filter the dialogues of a particular length (just to make those examples long enough and, at the same time, easy to read). Then wrap each dialogue with the instruction and tokenize the prompts. Save the token ids in the field `input_ids` and decoded version of the prompts in the field `query`.\n",
    "\n",
    "You could do that all step by step in the cell below, but it is a good habit to organize that all in a function `build_dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 12460/12460 [00:00<00:00, 119340.03 examples/s]\n",
      "Map: 100%|██████████| 10022/10022 [00:12<00:00, 777.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
      "        num_rows: 8017\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
      "        num_rows: 2005\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(model_name,\n",
    "                  dataset_name,\n",
    "                  input_min_text_length, \n",
    "                  input_max_text_length):\n",
    "\n",
    "    \"\"\"\n",
    "    Preprocess the dataset and split it into train and test parts.\n",
    "\n",
    "    Parameters:\n",
    "    - model_name (str): Tokenizer model name.\n",
    "    - dataset_name (str): Name of the dataset to load.\n",
    "    - input_min_text_length (int): Minimum length of the dialogues.\n",
    "    - input_max_text_length (int): Maximum length of the dialogues.\n",
    "        \n",
    "    Returns:\n",
    "    - dataset_splits (datasets.dataset_dict.DatasetDict): Preprocessed dataset containing train and test parts.\n",
    "    \"\"\"\n",
    "    \n",
    "    # load dataset (only \"train\" part will be enough for this lab).\n",
    "    dataset = load_dataset(dataset_name, split=\"train\")\n",
    "    \n",
    "    # Filter the dialogues of length between input_min_text_length and input_max_text_length characters.\n",
    "    dataset = dataset.filter(lambda x: len(x[\"dialogue\"]) > input_min_text_length and len(x[\"dialogue\"]) <= input_max_text_length, batched=False)\n",
    "\n",
    "    # Prepare tokenizer. Setting device_map=\"auto\" allows to switch between GPU and CPU automatically.\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "    \n",
    "    def tokenize(sample):\n",
    "        \n",
    "        # Wrap each dialogue with the instruction.\n",
    "        prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{sample[\"dialogue\"]}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "        sample[\"input_ids\"] = tokenizer.encode(prompt)\n",
    "        \n",
    "        # This must be called \"query\", which is a requirement of our PPO library.\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    # Tokenize each dialogue.\n",
    "    dataset = dataset.map(tokenize, batched=False)\n",
    "    dataset.set_format(type=\"torch\")\n",
    "    \n",
    "    # Split the dataset into train and test parts.\n",
    "    dataset_splits = dataset.train_test_split(test_size=0.2, shuffle=False, seed=42)\n",
    "\n",
    "    return dataset_splits\n",
    "\n",
    "dataset = build_dataset(model_name=model_name,\n",
    "                        dataset_name=huggingface_dataset_name,\n",
    "                        input_min_text_length=200, \n",
    "                        input_max_text_length=1000)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a function to pull out the number of model parameters (it is the same as in the previous lab):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"\\ntrainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the adapter to the original FLAN-T5 model. In the previous lab you were adding the fully trained adapter only for inferences, so there was no need to pass LoRA configurations doing that. Now you need to pass them to the constructed PEFT model, also putting `is_trainable=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT model parameters to be updated:\n",
      "\n",
      "trainable model parameters: 3538944\n",
      "all model parameters: 251116800\n",
      "percentage of trainable model parameters: 1.41%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, \n",
    "                                              torch_dtype=torch.bfloat16)\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(model, \n",
    "                                       '../peft-dialogue-summary-checkpoint-from-s3/', \n",
    "                                       lora_config=lora_config,\n",
    "                                       torch_dtype=torch.bfloat16, \n",
    "                                       device_map=\"auto\",                                       \n",
    "                                       is_trainable=True)\n",
    "\n",
    "print(f'PEFT model parameters to be updated:\\n{print_number_of_trainable_model_parameters(peft_model)}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you are preparing to fine-tune the LLM using Reinforcement Learning (RL). RL will be briefly discussed in the next section of this lab, but at this stage, you just need to prepare the Proximal Policy Optimization (PPO) model passing the instruct-fine-tuned PEFT model to it. PPO will be used to optimize the RL policy against the reward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO model parameters to be updated (ValueHead + 769 params):\n",
      "\n",
      "trainable model parameters: 3539713\n",
      "all model parameters: 251117569\n",
      "percentage of trainable model parameters: 1.41%\n",
      "\n",
      "ValueHead(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (summary): Linear(in_features=768, out_features=1, bias=True)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_model,                                                               \n",
    "                                                               torch_dtype=torch.bfloat16,\n",
    "                                                               is_trainable=True)\n",
    "\n",
    "print(f'PPO model parameters to be updated (ValueHead + 769 params):\\n{print_number_of_trainable_model_parameters(ppo_model)}\\n')\n",
    "print(ppo_model.v_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During PPO, only a few parameters will be updated. Specifically, the parameters of the `ValueHead`. More information about this class of models can be found in the [documentation](https://huggingface.co/docs/trl/main/en/models#trl.create_reference_model). The number of trainable parameters can be computed as $(n+1)*m$, where $n$ is the number of input units (here $n=768$) and $m$ is the number of output units (you have $m=1$). The $+1$ term in the equation takes into account the bias term.\n",
    "\n",
    "Now create a frozen copy of the PPO which will not be fine-tuned - a reference model. The reference model will represent the LLM before detoxification. None of the parameters of the reference model will be updated during PPO training. This is on purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference model parameters to be updated:\n",
      "\n",
      "trainable model parameters: 0\n",
      "all model parameters: 251117569\n",
      "percentage of trainable model parameters: 0.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ref_model = create_reference_model(ppo_model)\n",
    "\n",
    "print(f'Reference model parameters to be updated:\\n{print_number_of_trainable_model_parameters(ref_model)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Prepare Reward Model\n",
    "\n",
    "**Reinforcement Learning (RL)** is one type of machine learning where agents take actions in an environment aimed at maximizing their cumulative rewards. The agent's behavior is defined by the **policy**. And the goal of reinforcement learning is for the agent to learn an optimal, or nearly-optimal, policy that maximizes the **reward function**. \n",
    "\n",
    "In the [previous section](#2.1) the original policy is based on the instruct PEFT model - this is the LLM before detoxification. Then you could ask human labelers to give feedback on the outputs' toxicity. However, it can be expensive to use them for the entire fine-tuning process. A practical way to avoid that is to use a reward model encouraging the agent to detoxify the dialogue summaries. The intuitive approach would be to do some form of sentiment analysis across two classes (`nothate` and `hate`) and give a higher reward if there is higher a chance of getting class `nothate` as an output. \n",
    "\n",
    "For example, we can mention that having human labelers for the entire finetuning process can be expensive. A practical way to avoid that is to use a reward model.\n",
    "\n",
    "use feedback generated by a model\n",
    "\n",
    "You will use [Meta AI's RoBERTa-based hate speech model](https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target) for the reward model. This model will output **logits** and then predict probabilities across two classes: `nothate` and `hate`. The logits of the output `nothate` will be taken as a positive reward. Then, the model will be fine-tuned with PPO using those reward values.\n",
    "\n",
    "Create the instance of the required model class for the RoBERTa model. You also need to load a tokenizer to test the model. Notice that the model label `0` will correspond to the class `nothate` and label `1` to the class `hate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rg255041\\AppData\\Local\\anaconda3\\envs\\PEFT\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rg255041\\.cache\\huggingface\\hub\\models--facebook--roberta-hate-speech-dynabench-r4-target. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'nothate', 1: 'hate'}\n"
     ]
    }
   ],
   "source": [
    "toxicity_model_name = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
    "toxicity_tokenizer = AutoTokenizer.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
    "toxicity_model = AutoModelForSequenceClassification.from_pretrained(toxicity_model_name, device_map=\"auto\")\n",
    "print(toxicity_model.config.id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take some non-toxic text, tokenize it, and pass it to the model. Print the output logits, probabilities, and the corresponding reward that will be used for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits [not hate, hate]: [3.1140995025634766, -2.489616632461548]\n",
      "probabilities [not hate, hate]: [0.9963293671607971, 0.0036706251557916403]\n",
      "reward (high): [3.1140995025634766]\n"
     ]
    }
   ],
   "source": [
    "non_toxic_text = \"#Person 1# tells Tommy that he didn't like the movie.\"\n",
    "\n",
    "toxicity_input_ids = toxicity_tokenizer(non_toxic_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "logits = toxicity_model(input_ids=toxicity_input_ids).logits\n",
    "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
    "\n",
    "# Print the probabilities for [not hate, hate]\n",
    "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "print(f'probabilities [not hate, hate]: {probabilities}')\n",
    "\n",
    "# get the logits for \"not hate\" - this is the reward!\n",
    "not_hate_index = 0\n",
    "nothate_reward = (logits[:, not_hate_index]).tolist()\n",
    "print(f'reward (high): {nothate_reward}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show a toxic comment.  This will have a low reward because it is more toxic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits [not hate, hate]: [-0.6921157240867615, 0.3722701370716095]\n",
      "probabilities [not hate, hate]: [0.2564722001552582, 0.7435278296470642]\n",
      "reward (low): [-0.6921157240867615]\n"
     ]
    }
   ],
   "source": [
    "toxic_text = \"#Person 1# tells Tommy that the movie was terrible, dumb and stupid.\"\n",
    "\n",
    "toxicity_input_ids = toxicity_tokenizer(toxic_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "logits = toxicity_model(toxicity_input_ids).logits\n",
    "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
    "\n",
    "# Print the probabilities for [not hate, hate]\n",
    "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "print(f'probabilities [not hate, hate]: {probabilities}')\n",
    "\n",
    "# Get the logits for \"not hate\" - this is the reward!\n",
    "nothate_reward = (logits[:, not_hate_index]).tolist() \n",
    "print(f'reward (low): {nothate_reward}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Hugging Face inference pipeline to simplify the code for the toxicity reward model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward model output:\n",
      "For non-toxic text\n",
      "[{'label': 'nothate', 'score': 3.1140995025634766}, {'label': 'hate', 'score': -2.489616632461548}]\n",
      "[{'label': 'nothate', 'score': 0.9963293671607971}, {'label': 'hate', 'score': 0.0036706249229609966}]\n",
      "For toxic text\n",
      "[{'label': 'hate', 'score': 0.3722701370716095}, {'label': 'nothate', 'score': -0.6921157240867615}]\n",
      "[{'label': 'hate', 'score': 0.7435278296470642}, {'label': 'nothate', 'score': 0.2564722001552582}]\n"
     ]
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\", \n",
    "                          model=toxicity_model_name, \n",
    "                          device=device)\n",
    "reward_logits_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"none\", # Set to \"none\" to retrieve raw logits.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "reward_probabilities_kwargs = {\n",
    "    \"top_k\": None, # Return all scores.\n",
    "    \"function_to_apply\": \"softmax\", # Set to \"softmax\" to apply softmax and retrieve probabilities.\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "print(\"Reward model output:\")\n",
    "print(\"For non-toxic text\")\n",
    "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(non_toxic_text, **reward_probabilities_kwargs))\n",
    "print(\"For toxic text\")\n",
    "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are the logits for both `nothate` (positive) and `hate` (negative) classes. But PPO will be using logits only of the `nothate` class as the positive reward signal used to help detoxify the LLM outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'nothate', 'score': 3.1140995025634766}, {'label': 'hate', 'score': -2.489616632461548}]\n",
      "[{'label': 'nothate', 'score': 0.9963293671607971}, {'label': 'hate', 'score': 0.0036706249229609966}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(non_toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'hate', 'score': 0.3722701370716095}, {'label': 'nothate', 'score': -0.6921157240867615}]\n",
      "[{'label': 'hate', 'score': 0.7435278296470642}, {'label': 'nothate', 'score': 0.2564722001552582}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(toxic_text, **reward_probabilities_kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Evaluate Toxicity\n",
    "\n",
    "To evaluate the model before and after fine-tuning/detoxification you need to set up the [toxicity evaluation metric](https://huggingface.co/spaces/evaluate-measurement/toxicity). The **toxicity score** is a decimal value between 0 and 1 where 1 is the highest toxicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 6.08k/6.08k [00:00<?, ?B/s]\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "toxicity_evaluator = evaluate.load(\"toxicity\", \n",
    "                                    toxicity_model_name,\n",
    "                                    module_type=\"measurement\",\n",
    "                                    toxic_label=\"hate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to calculate toxicity for the same sentences as in section 2.2. It's no surprise that the toxicity scores are the probabilities of `hate` class returned directly from the reward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity score for non-toxic text:\n",
      "[0.0036706249229609966]\n",
      "\n",
      "Toxicity score for toxic text:\n",
      "[0.7435278296470642]\n"
     ]
    }
   ],
   "source": [
    "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
    "    non_toxic_text\n",
    "])\n",
    "\n",
    "print(\"Toxicity score for non-toxic text:\")\n",
    "print(toxicity_score[\"toxicity\"])\n",
    "\n",
    "toxicity_score = toxicity_evaluator.compute(predictions=[\n",
    "    toxic_text\n",
    "])\n",
    "\n",
    "print(\"\\nToxicity score for toxic text:\")\n",
    "print(toxicity_score[\"toxicity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This evaluator can be used to compute the toxicity of the dialogues prepared in section 2.1. You will need to pass the test dataset (`dataset[\"test\"]`), the same tokenizer which was used in that section, the frozen PEFT model prepared in section 2.2, and the toxicity evaluator. It is convenient to wrap the required steps in the function `evaluate_toxicity`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_toxicity(model, \n",
    "                      toxicity_evaluator, \n",
    "                      tokenizer, \n",
    "                      dataset, \n",
    "                      num_samples):\n",
    "    \n",
    "    \"\"\"\n",
    "    Preprocess the dataset and split it into train and test parts.\n",
    "\n",
    "    Parameters:\n",
    "    - model (trl model): Model to be evaluated.\n",
    "    - toxicity_evaluator (evaluate_modules toxicity metrics): Toxicity evaluator.\n",
    "    - tokenizer (transformers tokenizer): Tokenizer to be used.\n",
    "    - dataset (dataset): Input dataset for the evaluation.\n",
    "    - num_samples (int): Maximum number of samples for the evaluation.\n",
    "        \n",
    "    Returns:\n",
    "    tuple: A tuple containing two numpy.float64 values:\n",
    "    - mean (numpy.float64): Mean of the samples toxicity.\n",
    "    - std (numpy.float64): Standard deviation of the samples toxicity.\n",
    "    \"\"\"\n",
    "\n",
    "    max_new_tokens=100\n",
    "\n",
    "    toxicities = []\n",
    "    input_texts = []\n",
    "    for i, sample in tqdm(enumerate(dataset)):\n",
    "        input_text = sample[\"query\"]\n",
    "\n",
    "        if i > num_samples:\n",
    "            break\n",
    "            \n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\", padding=True).input_ids\n",
    "        \n",
    "        generation_config = GenerationConfig(max_new_tokens=max_new_tokens,\n",
    "                                             tok_k=0.0,\n",
    "                                             top_p=1.0,\n",
    "                                             do_sample=True)\n",
    "\n",
    "        response_token_ids = model.generate(input_ids=input_ids,\n",
    "                                            generation_config=generation_config)\n",
    "        \n",
    "        generated_text = tokenizer.decode(response_token_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        toxicity_score = toxicity_evaluator.compute(predictions=[(input_text + \" \" + generated_text)])\n",
    "\n",
    "        toxicities.extend(toxicity_score[\"toxicity\"])\n",
    "\n",
    "    # Compute mean & std using np.\n",
    "    mean = np.mean(toxicities)\n",
    "    std = np.std(toxicities)\n",
    "        \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now perform the calculation of the model toxicity before fine-tuning/detoxification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:22,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicity [mean, std] before detox: [0.028972376497801055, 0.03377996083630064]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "mean_before_detoxification, std_before_detoxification = evaluate_toxicity(model=ref_model, \n",
    "                                                                          toxicity_evaluator=toxicity_evaluator, \n",
    "                                                                          tokenizer=tokenizer, \n",
    "                                                                          dataset=dataset[\"test\"], \n",
    "                                                                          num_samples=10)\n",
    "\n",
    "print(f'toxicity [mean, std] before detox: [{mean_before_detoxification}, {std_before_detoxification}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PEFT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
